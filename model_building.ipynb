{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: numpy in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.5.1+cu121 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.5.1+cu121)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1+cu121->torchvision) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1+cu121->torchvision) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1+cu121->torchvision) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1+cu121->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1+cu121->torchvision) (2025.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch==2.5.1+cu121->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1+cu121->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch==2.5.1+cu121->torchvision) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1764672485919,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "M_zwS0NflHlx"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1764672487092,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "6hDKTFZ9lWjr"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# transforms (you already have similar)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1764672489040,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "buNbqlEalbRn"
   },
   "outputs": [],
   "source": [
    "class SingleImageEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256, pretrained=True):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.DEFAULT if pretrained else None)\n",
    "        for param in base.parameters():\n",
    "            param.requires_grad = False\n",
    "        # replace final fc with embed\n",
    "        base.fc = nn.Linear(base.fc.in_features, embed_dim)\n",
    "        self.model = base\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        return self.model(x)  # (B, embed_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1764672490502,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "G5shQ9XclfrH"
   },
   "outputs": [],
   "source": [
    "class SimpleGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden, out_feats, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_feats, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, out_feats)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, A_norm, X):\n",
    "        # A_norm: (N,N) normalized adjacency (symmetric)\n",
    "        # X: (N, in_feats)\n",
    "        h = self.fc1(torch.matmul(A_norm, X))   # (N, hidden)\n",
    "        h = F.relu(h)\n",
    "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
    "        h = self.fc2(torch.matmul(A_norm, h))   # (N, out_feats)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1764672492113,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "NXWUoTKpljqm"
   },
   "outputs": [],
   "source": [
    "class CombinedEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256, gcn_hidden=128, gcn_out=256, node_feat_dim=None):\n",
    "        super().__init__()\n",
    "        self.image_encoder = SingleImageEncoder(embed_dim=embed_dim)\n",
    "        # project concatenated image features + KG into final embed_dim\n",
    "        concat_dim = embed_dim * 2 + gcn_out\n",
    "        self.proj = nn.Linear(concat_dim, embed_dim)\n",
    "        # GCN: input node feature dim = node_feat_dim\n",
    "        if node_feat_dim is None:\n",
    "            node_feat_dim = gcn_out\n",
    "        self.gcn = SimpleGCN(in_feats=node_feat_dim, hidden=gcn_hidden, out_feats=gcn_out)\n",
    "\n",
    "    def forward(self, img1, img2, A_norm, node_feats):\n",
    "        # img1, img2: (B,C,H,W) — here we'll support B=1 in inference, but supports batch\n",
    "        f1 = self.image_encoder(img1)  # (B, embed_dim)\n",
    "        f2 = self.image_encoder(img2)  # (B, embed_dim)\n",
    "\n",
    "        # KG: run GCN on node_feats A_norm to get per-node embeddings\n",
    "        # node_feats: (N, node_feat_dim)\n",
    "        # gcn returns (N, gcn_out). We need a single KG embedding vector to serve as prior;\n",
    "        # simplest: mean-pool node embeddings (or you can pick a subgraph)\n",
    "        kg_node_embs = self.gcn(A_norm, node_feats)  # (N, gcn_out)\n",
    "        kg_emb = kg_node_embs.mean(dim=0, keepdim=True)  # (1, gcn_out)\n",
    "        # expand across batch\n",
    "        B = f1.shape[0]\n",
    "        kg_emb = kg_emb.expand(B, -1)  # (B, gcn_out)\n",
    "\n",
    "        # concat and project\n",
    "        cat = torch.cat([f1, f2, kg_emb], dim=1)  # (B, 2*embed + gcn_out)\n",
    "        combined = torch.tanh(self.proj(cat))     # (B, embed_dim)\n",
    "        return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1764672494348,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "8pVPZrfblqUy"
   },
   "outputs": [],
   "source": [
    "class ReportDecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_dim, vocab_size, hidden_dim=512):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        # self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, dropout=0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.init_fc = nn.Linear(embed_dim, hidden_dim)  # takes the combined feature vector\n",
    "    def forward(self, features, captions):\n",
    "        # features: (B, embed_dim)\n",
    "        embeddings = self.embedding(captions)  # (B, T, embed_dim)\n",
    "        h0 = torch.tanh(self.init_fc(features)).unsqueeze(0)  # (1, B, hidden_dim)\n",
    "        c0 = torch.zeros_like(h0)\n",
    "        outputs, _ = self.lstm(embeddings, (h0, c0))\n",
    "        logits = self.fc(outputs)  # (B, T, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1764672496829,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "q15ACP6Jl4_L"
   },
   "outputs": [],
   "source": [
    "def load_adj_and_node_features(csv_path, device, node_feat_mode='onehot', max_onehot_nodes=1000):\n",
    "    A = pd.read_csv(csv_path, header=None).values.astype(np.float32)\n",
    "    N = A.shape[0]\n",
    "    assert A.shape[0] == A.shape[1], \"Adjacency matrix must be square.\"\n",
    "    # add self loops\n",
    "    A_hat = A + np.eye(N, dtype=np.float32)\n",
    "    deg = A_hat.sum(axis=1)\n",
    "    # D^-0.5 * A_hat * D^-0.5\n",
    "    D_inv_sqrt = np.diag(1.0 / np.sqrt(deg + 1e-12))\n",
    "    A_norm = D_inv_sqrt @ A_hat @ D_inv_sqrt\n",
    "    A_norm = torch.from_numpy(A_norm).to(device)\n",
    "\n",
    "    # node features\n",
    "    if node_feat_mode == 'onehot' and N <= max_onehot_nodes:\n",
    "        node_feats = np.eye(N, dtype=np.float32)  # (N, N) -> onehot\n",
    "    elif node_feat_mode == 'degree':\n",
    "        node_feats = deg.reshape(-1, 1).astype(np.float32)  # (N,1)\n",
    "    else:\n",
    "        # fallback: identity features of small dim (here use normalized degree + ones)\n",
    "        node_feats = np.stack([deg / (deg.max() + 1e-12), np.ones_like(deg)], axis=1).astype(np.float32)  # (N,2)\n",
    "    node_feats = torch.from_numpy(node_feats).to(device)\n",
    "    return A_norm, node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1764672498620,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "JRFWyecvW5jw"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "special_tokens = {\n",
    "    \"bos_token\": \"<BOS>\",\n",
    "    \"eos_token\": \"<EOS>\"\n",
    "}\n",
    "\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "vocab_size = len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1764672499679,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "7rHuNpVpIbvf"
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch, tokenizer):\n",
    "    img1_list, img2_list = [], []\n",
    "    rep_list = []\n",
    "    ground_truth_list = []\n",
    "    img1_paths, img2_paths = [], []\n",
    "\n",
    "    BOS = tokenizer.bos_token_id     # e.g., 1\n",
    "    EOS = tokenizer.eos_token_id     # e.g., 2\n",
    "    PAD = tokenizer.pad_token_id     # e.g., 0\n",
    "\n",
    "    for item in batch:\n",
    "        img1_list.append(item[\"img1\"])\n",
    "        img2_list.append(item[\"img2\"])\n",
    "        ground_truth_list.append(item[\"report\"])\n",
    "        img1_paths.append(item[\"img1_path\"])\n",
    "        img2_paths.append(item[\"img2_path\"])\n",
    "\n",
    "        text = item[\"findings\"].strip()\n",
    "\n",
    "        # Encode without special tokens\n",
    "        ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "\n",
    "        # Add BOS/EOS manually\n",
    "        ids = [BOS] + ids + [EOS]\n",
    "\n",
    "        rep_list.append(torch.tensor(ids, dtype=torch.long))\n",
    "\n",
    "    # Stack images\n",
    "    img1_batch = torch.stack(img1_list)\n",
    "    img2_batch = torch.stack(img2_list)\n",
    "\n",
    "    # Pad token sequence\n",
    "    rep_padded = pad_sequence(rep_list, batch_first=True, padding_value=PAD)\n",
    "\n",
    "    return {\n",
    "        \"img1\": img1_batch,\n",
    "        \"img2\": img2_batch,\n",
    "        \"tokens\": rep_padded,\n",
    "        \"report\": ground_truth_list,\n",
    "        \"img1_path\": img1_paths,\n",
    "        \"img2_path\": img2_paths\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1764672501459,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "hnz_7CqeIp6W"
   },
   "outputs": [],
   "source": [
    "class MIMICCXRDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # =========================\n",
    "        # LOAD IMAGES\n",
    "        # =========================\n",
    "        img_paths = row[\"image_path\"]\n",
    "\n",
    "        # Ensure two views\n",
    "        if len(img_paths) == 0:\n",
    "            raise ValueError(f\"No images found for index {idx}\")\n",
    "\n",
    "        if len(img_paths) == 1:\n",
    "            img1_path = img_paths[0]\n",
    "            img2_path = img_paths[0]     # duplicate\n",
    "        else:\n",
    "            img1_path, img2_path = img_paths[:2]\n",
    "\n",
    "        # Load and convert to RGB\n",
    "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
    "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        # =========================\n",
    "        # TEXT FIELDS\n",
    "        # =========================\n",
    "        history = str(row.get(\"history\", \"\")).strip()\n",
    "        findings = str(row.get(\"findings\", \"\")).strip()\n",
    "        impression = str(row.get(\"impression\", \"\")).strip()\n",
    "        # print(f\"Inside dataset __getitem__, findings={findings} ,history={history}, impression={impression}\")\n",
    "\n",
    "        # =========================\n",
    "        # FINAL REPORT\n",
    "        # =========================\n",
    "        # if findings or impression:\n",
    "        #     final_report = (findings + \" \" + impression).strip()\n",
    "        # else:\n",
    "        #     final_report = str(row.get(\"report_text\", \"\")).strip()\n",
    "        final_report = str(row.get(\"report_text\", \"\")).strip()\n",
    "\n",
    "        return {\n",
    "            \"img1\": img1,\n",
    "            \"img2\": img2,\n",
    "            \"history\": history,\n",
    "            \"findings\": findings,\n",
    "            \"impression\": impression,\n",
    "            \"report\": final_report,\n",
    "            \"img1_path\": img1_path,\n",
    "            \"img2_path\": img2_path\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 178360,
     "status": "ok",
     "timestamp": 1764646091030,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "x2IIclj8aKoB",
    "outputId": "1d6ef152-f6bc-419a-9732-d9989e969212"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\n"
     ]
    }
   ],
   "source": [
    "path = r\"D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\"\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1764646091031,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "xkuErYPtdlPe",
    "outputId": "79d9aa7d-4cd8-4f7e-eb65-fde36388f198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files/folders inside base path:\n",
      "['metadata.csv', 'mimic-cxr-reports', 'official_data_iccv_final']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Files/folders inside base path:\")\n",
    "print(os.listdir(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1764646091051,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "6e461M-QaLtv",
    "outputId": "420efe62-f958-4901-f43f-0c82264d0ab2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reports: D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\mimic-cxr-reports/files\n",
      "Images: D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\official_data_iccv_final/files\n",
      "Metadata: D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\metadata.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "BASE_PATH = os.path.join(path, \"mimic-cxr-reports/files\")\n",
    "IMG_PATH  = os.path.join(path, \"official_data_iccv_final/files\")   # or check actual folder name\n",
    "META_PATH = os.path.join(path, \"metadata.csv\")\n",
    "\n",
    "print(\"Reports:\", BASE_PATH)\n",
    "print(\"Images:\", IMG_PATH)\n",
    "print(\"Metadata:\", META_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1764646091064,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "6RtmAwJGLgUS",
    "outputId": "d9c115e1-4bbb-494d-9bd4-b969bac401e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17', 'p18', 'p19']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1764646091089,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "1poix_c-O_um",
    "outputId": "7129cf63-5722-4444-e210-5b9e64c2161c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s52487079.txt', 's54824507.txt', 's57315885.txt']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(r\"D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\mimic-cxr-reports\\files\\p17\\p17702631\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42591,
     "status": "ok",
     "timestamp": 1764646133694,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "j29M2fuQ-05m",
    "outputId": "fe049bdd-101d-4908-8131-bdd5a202ec37"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "import os, math, random, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "\n",
    "# ==== LOCAL PATHS ====\n",
    "REPORTS_DIR = r\"D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\mimic-cxr-reports\\files\"\n",
    "IMAGES_DIR = r\"D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\official_data_iccv_final\\files\"\n",
    "METADATA_PATH = r\"D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\metadata.csv\"\n",
    "\n",
    "# Directory to save trained models\n",
    "SAVED_MODELS_DIR = \"./saved_models\"\n",
    "os.makedirs(SAVED_MODELS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 488,
     "status": "ok",
     "timestamp": 1764646134172,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "dss38qs5hUmm",
    "outputId": "5d8bd0cf-1519-480f-cf1b-6a8e04ff2e9d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardiomegaly</th>\n",
       "      <th>pleural effusion</th>\n",
       "      <th>consolidation</th>\n",
       "      <th>atelectasis</th>\n",
       "      <th>pneumothorax</th>\n",
       "      <th>normal heart</th>\n",
       "      <th>normal lungs</th>\n",
       "      <th>opacity</th>\n",
       "      <th>emphysema</th>\n",
       "      <th>enlarged heart</th>\n",
       "      <th>...</th>\n",
       "      <th>evidence</th>\n",
       "      <th>process</th>\n",
       "      <th>cardiopulmonary</th>\n",
       "      <th>small</th>\n",
       "      <th>tube</th>\n",
       "      <th>hilar</th>\n",
       "      <th>stable</th>\n",
       "      <th>prior</th>\n",
       "      <th>upper</th>\n",
       "      <th>lobe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cardiomegaly  pleural effusion  consolidation  atelectasis  pneumothorax  \\\n",
       "0             0                 1              0            0             0   \n",
       "1             1                 0              1            1             1   \n",
       "2             0                 1              0            0             1   \n",
       "3             0                 1              0            0             1   \n",
       "4             0                 1              1            1             0   \n",
       "\n",
       "   normal heart  normal lungs  opacity  emphysema  enlarged heart  ...  \\\n",
       "0             0             0        0          0               0  ...   \n",
       "1             0             0        1          0               0  ...   \n",
       "2             0             0        0          0               0  ...   \n",
       "3             0             0        0          0               0  ...   \n",
       "4             0             0        1          0               0  ...   \n",
       "\n",
       "   evidence  process  cardiopulmonary  small  tube  hilar  stable  prior  \\\n",
       "0         0        0                0      0     0      0       0      0   \n",
       "1         1        1                1      1     1      1       1      1   \n",
       "2         0        1                1      0     0      1       0      0   \n",
       "3         0        0                0      0     0      0       0      0   \n",
       "4         1        1                1      1     1      1       1      1   \n",
       "\n",
       "   upper  lobe  \n",
       "0      0     0  \n",
       "1      1     1  \n",
       "2      0     0  \n",
       "3      0     0  \n",
       "4      1     1  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_kg = pd.read_csv(r\"D:\\fyp_manish_shyam\\adjacency_matrix.csv\")\n",
    "df_kg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1764672514849,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "vOuwwldn_a-F",
    "outputId": "67b4cfc6-8c36-4cbe-9af6-c312eada2bbc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix shape: (45, 45)\n",
      "A_hat ready for GCN: torch.Size([45, 45])\n",
      "Sample terms: ['node_0', 'node_1', 'node_2', 'node_3', 'node_4'] ...\n",
      "Embedding KG terms on CPU (MiniLM)...\n",
      "Node features shape: torch.Size([45, 384])\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Load adjacency matrix (df_kg)\n",
    "# -----------------------------------------------------\n",
    "A = df_kg.values.astype(float)\n",
    "N = A.shape[0]\n",
    "print(\"Adjacency matrix shape:\", A.shape)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Make symmetric + normalize (GCN normalization)\n",
    "# -----------------------------------------------------\n",
    "A = (A + A.T) / 2.0\n",
    "A += np.eye(N) * 1e-6  # prevent zero degree\n",
    "\n",
    "D = np.sum(A, axis=1)\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(D + 1e-8))\n",
    "A_hat = D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "A_hat = torch.tensor(A_hat, dtype=torch.float32)\n",
    "print(\"A_hat ready for GCN:\", A_hat.shape)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Dummy node names if you don't have real terms\n",
    "# -----------------------------------------------------\n",
    "terms = [f\"node_{i}\" for i in range(N)]\n",
    "print(\"Sample terms:\", terms[:5], \"...\")\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. TEXT EMBEDDING — FORCED CPU (fix for GTX 1080 Ti)\n",
    "# -----------------------------------------------------\n",
    "tokenizer_term = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# IMPORTANT: Load the transformer on CPU ONLY\n",
    "text_model = AutoModel.from_pretrained(\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ").to(\"cpu\")\n",
    "text_model.eval()\n",
    "\n",
    "\n",
    "def embed_terms(terms_list):\n",
    "    \"\"\"Compute MiniLM embeddings on CPU (works for older GPUs).\"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # tokenize\n",
    "    enc = tokenizer_term(\n",
    "        terms_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # run transformer on CPU\n",
    "        out = text_model(\n",
    "            input_ids=enc[\"input_ids\"].to(device),\n",
    "            attention_mask=enc[\"attention_mask\"].to(device)\n",
    "        )\n",
    "\n",
    "        mask = enc[\"attention_mask\"].unsqueeze(-1).to(device)\n",
    "        token_embeds = out.last_hidden_state * mask\n",
    "\n",
    "        summed = token_embeds.sum(1)\n",
    "        counts = mask.sum(1).clamp(min=1)\n",
    "\n",
    "        # mean-pooled sentence embeddings\n",
    "        pooled = summed / counts   # stays on CPU\n",
    "\n",
    "    return pooled  # (N, 384)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Compute node embeddings\n",
    "# -----------------------------------------------------\n",
    "print(\"Embedding KG terms on CPU (MiniLM)...\")\n",
    "X_nodes = embed_terms(terms)\n",
    "\n",
    "print(\"Node features shape:\", X_nodes.shape)\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1764672517761,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "so_GLIz7_idC",
    "outputId": "12f139c8-a3b9-40ef-d03a-8edb5fffa0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw A shape: (45, 45)\n",
      "A_hat shape: torch.Size([45, 45])\n",
      "[[6.666662102361443e-07, 0.09491576254367828, 0.0, 0.0, 0.0], [0.09491576254367828, 5.4054051901175626e-08, 0.03355779871344566, 0.039872609078884125, 0.027399830520153046], [0.0, 0.03355779871344566, 8.333332601750953e-08, 0.0, 0.03402068838477135], [0.0, 0.039872609078884125, 0.0, 1.1764704765937495e-07, 0.040422599762678146], [0.0, 0.027399830520153046, 0.03402068838477135, 0.040422599762678146, 5.5555553046815476e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Build normalized adjacency A_hat from the binary numpy array A\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"Raw A shape:\", A.shape)\n",
    "\n",
    "# --- 1) Ensure A is numpy float array ---\n",
    "A = A.astype(float)\n",
    "\n",
    "# --- 2) Add small self-loops ---\n",
    "eps = 1e-6\n",
    "A_with_loops = A + np.eye(A.shape[0]) * eps\n",
    "\n",
    "# --- 3) Compute degree matrix ---\n",
    "deg = A_with_loops.sum(axis=1)\n",
    "D_inv_sqrt = np.diag(1.0 / np.sqrt(deg + 1e-8))\n",
    "\n",
    "# --- 4) Symmetric normalization: A_hat = D^-1/2 * A * D^-1/2 ---\n",
    "A_hat_np = D_inv_sqrt @ A_with_loops @ D_inv_sqrt\n",
    "\n",
    "# --- 5) Convert to torch tensor ---\n",
    "A_hat = torch.tensor(A_hat_np, dtype=torch.float32)\n",
    "\n",
    "print(\"A_hat shape:\", A_hat.shape)\n",
    "print(A_hat[:5, :5].tolist())\n",
    "  # preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPORT_PATH = os.path.join(path, \"mimic-cxr-reports\", \"files\")\n",
    "# IMAGE_PATH = os.path.join(path, \"official_data_iccv_final\", \"files\")\n",
    "# META_PATH = os.path.join(path, \"mimic-cxr-metadata.csv\")\n",
    "# print(REPORT_PATH)\n",
    "# print(IMAGE_PATH)\n",
    "# print(META_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# all_reports = []\n",
    "# all_report_paths = []\n",
    "# all_image_paths = []\n",
    "# all_patient_ids = []\n",
    "# all_study_ids = []\n",
    "\n",
    "# for pid in os.listdir(REPORT_PATH):  # REPORT_PATH = mimic-cxr-reports/files\n",
    "#     pid_path = os.path.join(REPORT_PATH, pid)\n",
    "#     if not os.path.isdir(pid_path):\n",
    "#         continue\n",
    "\n",
    "#     for patient in os.listdir(pid_path):  # e.g., p11013572\n",
    "#         patient_path = os.path.join(pid_path, patient)\n",
    "#         if not os.path.isdir(patient_path):\n",
    "#             continue\n",
    "#         # print(patient_path)\n",
    "\n",
    "#         for study_file in os.listdir(patient_path):  # e.g., s50771383.txt\n",
    "#             if study_file.endswith(\".txt\"):\n",
    "#                 report_path = os.path.join(patient_path, study_file)\n",
    "#                 study_id = study_file[:-4]  # remove '.txt'\n",
    "#                 # print(study_id)\n",
    "\n",
    "#                 # Build corresponding image folder path\n",
    "#                 image_folder_path = os.path.join(\n",
    "#                     IMAGE_PATH,  # /mimic-cxr-dataset/official_data_iccv_final/files\n",
    "#                     pid,\n",
    "#                     patient,\n",
    "#                     study_id\n",
    "#                 )\n",
    "#                 # print(image_folder_path)\n",
    "\n",
    "#                 # Only proceed if image folder exists\n",
    "#                 if os.path.exists(image_folder_path):\n",
    "#                     # print('im here')\n",
    "#                     image_files = [f for f in os.listdir(image_folder_path) if f.lower().endswith('.jpg')]\n",
    "#                     for image_file in image_files:\n",
    "#                         image_path = os.path.join(image_folder_path, image_file)\n",
    "#                         # print(image_path)\n",
    "\n",
    "#                         with open(report_path, \"r\") as f:\n",
    "#                             report_text = f.read()\n",
    "\n",
    "#                         all_reports.append(report_text)\n",
    "#                         all_report_paths.append(report_path)\n",
    "#                         all_image_paths.append(image_path)\n",
    "#                         all_patient_ids.append(patient)\n",
    "#                         all_study_ids.append(study_id)\n",
    "\n",
    "# print(f\"\\nTotal valid (image + report) pairs: {len(all_reports)}\")\n",
    "# print(f\"\\nSample report text:\\n{all_reports[0][:500]}\")\n",
    "# print(f\"\\nSample image path:\\n{all_image_paths[0]}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# SECTION_NAMES = [\"HISTORY\", \"INDICATION\", \"FINDINGS\", \"IMPRESSION\", \"TECHNIQUE\", \"EXAMINATION\", \"COMPARISON\", \"REFERENCE EXAM\", \"COMPARISONS\"]\n",
    "\n",
    "# def extract_field(report: str, field: str):\n",
    "\n",
    "#     # INDICATION should match both INDICATION and HISTORY\n",
    "#     if field.upper() == \"INDICATION\":\n",
    "#         field_pattern = r\"(?:INDICATION|HISTORY)\"\n",
    "#     else:\n",
    "#         field_pattern = re.escape(field)\n",
    "\n",
    "#     # Build next-section pattern (case-insensitive)\n",
    "#     next_fields = \"|\".join([f\"{name}:\" for name in SECTION_NAMES])\n",
    "\n",
    "#     # Entire regex is case-insensitive with (?i) AT THE BEGINNING\n",
    "#     pattern = re.compile(\n",
    "#         rf\"(?i){field_pattern}:\\s*(.*?)(?=\\n\\s*(?:{next_fields})|\\Z)\",\n",
    "#         flags=re.DOTALL\n",
    "#     )\n",
    "\n",
    "#     match = pattern.search(report)\n",
    "#     if match:\n",
    "#         return match.group(1).strip()\n",
    "\n",
    "#     return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Step 1: Create initial dataframe (one row per image)\n",
    "# df = pd.DataFrame({\n",
    "#     \"patient_id\": all_patient_ids,\n",
    "#     \"study_id\": all_study_ids,\n",
    "#     \"report_text\": all_reports,\n",
    "#     \"report_path\": all_report_paths,\n",
    "#     \"image_path\": all_image_paths\n",
    "# })\n",
    "\n",
    "# # Step 2: Group by patient_id + study_id\n",
    "# df_new = df.groupby([\"patient_id\", \"study_id\"]).agg({\n",
    "#     \"image_path\": list,          # collect all image paths into list\n",
    "#     \"report_text\": \"first\",      # all same → pick first\n",
    "#     \"report_path\": \"first\"       # all same → pick first\n",
    "# }).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new[\"findings\"] = df_new[\"report_text\"].apply(lambda re: extract_field(re, \"FINDINGS\"))\n",
    "# df_new[\"impression\"] = df_new[\"report_text\"].apply(lambda re: extract_field(re, \"IMPRESSION\"))\n",
    "# df_new[\"history\"] = df_new[\"report_text\"].apply(lambda re: extract_field(re, \"INDICATION\"))\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.to_pickle(r\"D:\\fyp_manish_shyam\\df_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  patient_id   study_id                                         image_path  \\\n",
      "0  p10000032  s50414267  [D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset...   \n",
      "1  p10000032  s53189527  [D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset...   \n",
      "2  p10000032  s53911762  [D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset...   \n",
      "3  p10000032  s56699142  [D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset...   \n",
      "4  p10000898  s50771383  [D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset...   \n",
      "\n",
      "                                         report_text  \\\n",
      "0                                   FINAL REPORT\\...   \n",
      "1                                   FINAL REPORT\\...   \n",
      "2                                   FINAL REPORT\\...   \n",
      "3                                   FINAL REPORT\\...   \n",
      "4                                   FINAL REPORT\\...   \n",
      "\n",
      "                                         report_path  \\\n",
      "0  D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\...   \n",
      "1  D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\...   \n",
      "2  D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\...   \n",
      "3  D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\...   \n",
      "4  D:\\fyp_manish_shyam\\archive\\mimic-cxr-dataset\\...   \n",
      "\n",
      "                                            findings  \\\n",
      "0  there is no focal consolidation, pleural effus...   \n",
      "1  the cardiac, mediastinal and hilar contours ar...   \n",
      "2  single frontal view of the chest provided. the...   \n",
      "3  the lungs are clear of focal consolidation, pl...   \n",
      "4  pa and lateral views of the chest provided. lu...   \n",
      "\n",
      "                              impression  \\\n",
      "0      no acute cardiopulmonary process.   \n",
      "1  no acute cardiopulmonary abnormality.   \n",
      "2        no acute intrathoracic process.   \n",
      "3      no acute cardiopulmonary process.   \n",
      "4        no acute intrathoracic process.   \n",
      "\n",
      "                                          history  \n",
      "0  f with new onset ascites // eval for infection  \n",
      "1             history: f with shortness of breath  \n",
      "2                  f with cough // acute process?  \n",
      "3                  year old woman with cirrhosis.  \n",
      "4                       f with chest pain // ?pna  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_new = pd.read_pickle(r\"D:\\fyp_manish_shyam\\df_new.pkl\")\n",
    "\n",
    "print(df_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 683,
     "status": "ok",
     "timestamp": 1764672522080,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "IuRwYHTYw8HK",
    "outputId": "19aa4696-6f71-4e6c-a4e2-712b84799b11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 5244, Test batches: 1311\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# BUILD MODEL\n",
    "# ==============================\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "embed_dim = 256\n",
    "hidden_dim = 512\n",
    "\n",
    "encoder = CombinedEncoder(\n",
    "    embed_dim=embed_dim,\n",
    "    gcn_hidden=128,\n",
    "    gcn_out=256,\n",
    "    node_feat_dim=X_nodes.shape[1]\n",
    ").to(device)\n",
    "\n",
    "decoder = ReportDecoderRNN(\n",
    "    embed_dim=embed_dim,\n",
    "    vocab_size=vocab_size,\n",
    "    hidden_dim=hidden_dim\n",
    ").to(device)\n",
    "\n",
    "decoder.embedding.weight.requires_grad_(True)\n",
    "\n",
    "# ==============================\n",
    "# OPTIMIZER + LOSS\n",
    "# ==============================\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)   # ignore PAD token\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(encoder.parameters()) + list(decoder.parameters()),\n",
    "    lr=1e-4\n",
    ")\n",
    "\n",
    "A_hat = A_hat.to(device)\n",
    "X_nodes = X_nodes.to(device)\n",
    "\n",
    "# ==============================\n",
    "# SPLIT: 80% TRAIN, 20% TEST\n",
    "# ==============================\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df_new, test_size=0.20, random_state=42)\n",
    "\n",
    "train_dataset = MIMICCXRDataset(train_df, transform=transform)\n",
    "test_dataset  = MIMICCXRDataset(test_df,  transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True,\n",
    "                          collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "\n",
    "test_loader  = DataLoader(test_dataset, batch_size=8, shuffle=False,\n",
    "                          collate_fn=lambda x: collate_fn(x, tokenizer))\n",
    "\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1764656210967,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "u7oEKp3QsnS-"
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "# import pandas as pd\n",
    "\n",
    "# def clean_report(report: str) -> str:\n",
    "#     if not isinstance(report, str):\n",
    "#         return \"\"\n",
    "\n",
    "#     report = re.sub(r'_', ' ', report)          # Replace underscores with space\n",
    "#     report = re.sub(r'\\s+', ' ', report).strip()  # Normalize whitespace\n",
    "#     report = report.lower()                      # Convert to lowercase\n",
    "#     return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 1041,
     "status": "ok",
     "timestamp": 1764656216734,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "QZrfCS-PtMIK"
   },
   "outputs": [],
   "source": [
    "# # Example usage with a DataFrame\n",
    "# df_new['findings'] = df_new['findings'].apply(clean_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 2550,
     "status": "ok",
     "timestamp": 1764656273537,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "tFZLIlfztQe2",
    "outputId": "d8f43f4f-98e4-4390-f7a3-9fb1e64276c3"
   },
   "outputs": [],
   "source": [
    "# # Example usage with a DataFrame\n",
    "# df_new['history'] = df_new['history'].apply(clean_report)\n",
    "# df_new['history'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 1501,
     "status": "ok",
     "timestamp": 1764656307407,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "E8K5NMIKthjU",
    "outputId": "39dc0bf2-d618-4619-87d7-f66310fa679e"
   },
   "outputs": [],
   "source": [
    "# # Example usage with a DataFrame\n",
    "# df_new['impression'] = df_new['impression'].apply(clean_report)\n",
    "# df_new['impression'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new.to_pickle(r\"D:\\fyp_manish_shyam\\df_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1315821,
     "status": "ok",
     "timestamp": 1764673853327,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "2_Gt7R3KyCKX",
    "outputId": "2ecf5c2d-f221-4ef9-fec1-4fe159ca546a"
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "\n",
    "# num_epochs = 10\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     encoder.train()\n",
    "#     decoder.train()\n",
    "\n",
    "#     total_train_loss = 0\n",
    "#     total_tokens = 0\n",
    "\n",
    "#     # tqdm loader\n",
    "#     train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=True)\n",
    "\n",
    "    \n",
    "#     for batch in train_pbar:\n",
    "#         img1 = batch[\"img1\"].to(device)\n",
    "#         img2 = batch[\"img2\"].to(device)\n",
    "#         tokens = batch[\"tokens\"].to(device)   # (B, T)\n",
    "\n",
    "#         inputs = tokens[:, :-1]\n",
    "#         targets = tokens[:, 1:]\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # ===== ENCODER =====\n",
    "#         features = encoder(img1, img2, A_hat.to(device), X_nodes.to(device))  # (B, embed_dim)\n",
    "\n",
    "#         # ===== DECODER =====\n",
    "#         logits = decoder(features, inputs)  # (B, T-1, vocab)\n",
    "\n",
    "#         loss = criterion(\n",
    "#             logits.reshape(-1, vocab_size),\n",
    "#             targets.reshape(-1)\n",
    "#         )\n",
    "\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         total_train_loss += loss.item() * targets.numel()\n",
    "#         total_tokens += targets.numel()\n",
    "\n",
    "#         # update progress bar\n",
    "#         train_pbar.set_postfix({\n",
    "#             \"loss\": f\"{loss.item():.4f}\"\n",
    "#         })\n",
    "\n",
    "#     avg_train_loss = total_train_loss / total_tokens\n",
    "#     print(f\"\\n[Epoch {epoch+1}] Average Train Loss = {avg_train_loss:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1764671793457,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "_mmg-QVKr-z1",
    "outputId": "c72908bc-9c84-4578-cd6a-f1ec7d1b4a46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30522 30523\n",
      "101 102\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.bos_token_id, tokenizer.eos_token_id)\n",
    "print(tokenizer.cls_token_id, tokenizer.sep_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7220,
     "status": "ok",
     "timestamp": 1764675711438,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "SKfs-gRk5XiO",
    "outputId": "f4c2a58a-b2fa-4a06-a402-e93431df9309"
   },
   "outputs": [],
   "source": [
    "# save_path = r\"D:\\fyp_manish_shyam\\saved_models\\final_model.pth\"\n",
    "\n",
    "# checkpoint = {\n",
    "#     \"encoder_state_dict\": encoder.state_dict(),\n",
    "#     \"decoder_state_dict\": decoder.state_dict(),\n",
    "#     \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "#     \"vocab_size\": vocab_size,\n",
    "#     \"epoch\": epoch + 1\n",
    "# }\n",
    "\n",
    "# torch.save(checkpoint, save_path)\n",
    "\n",
    "# print(f\"Model saved successfully at: {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_7740\\591486831.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(save_path)\n"
     ]
    }
   ],
   "source": [
    "save_path = r\"D:\\fyp_manish_shyam\\saved_models\\final_model.pth\"\n",
    "checkpoint = torch.load(save_path)\n",
    "\n",
    "encoder.load_state_dict(checkpoint[\"encoder_state_dict\"])\n",
    "decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1764675454047,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "Dp8rLW9V51y4"
   },
   "outputs": [],
   "source": [
    "def generate_report(\n",
    "    encoder, decoder, img1, img2, A_hat, X_nodes,\n",
    "    max_len=80, temperature=1.0, min_len=10\n",
    "):\n",
    "    BOS = tokenizer.bos_token_id\n",
    "    EOS = tokenizer.eos_token_id\n",
    "    NONE_ID = tokenizer.encode(\"none\", add_special_tokens=False)[0]\n",
    "\n",
    "    # Encode image features\n",
    "    with torch.no_grad():\n",
    "        feat = encoder(img1, img2, A_hat, X_nodes)\n",
    "\n",
    "    generated = [BOS]\n",
    "    words = 0\n",
    "\n",
    "    p = 0.9   # nucleus threshold\n",
    "\n",
    "    \n",
    "    for _ in range(max_len):\n",
    "        # convert python list → tensor (1, T)\n",
    "        inp = torch.tensor(generated, dtype=torch.long, device=device).unsqueeze(0)\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            logits = decoder(feat, inp)  # (1, T, vocab)\n",
    "    \n",
    "        # use last token\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        logits = logits.squeeze(0) # added\n",
    "        if words < min_len:         # added\n",
    "            logits[EOS] = -1e9       # added\n",
    "            logits[NONE_ID] = -1e9       # added\n",
    "        probs = torch.softmax(logits, dim=-1) # added\n",
    "    \n",
    "        # # ----- Nucleus Sampling (Top-p) -----\n",
    "        # sorted_probs, sorted_idx = torch.sort(probs, descending=True)  # (1, V)\n",
    "        # cumulative = torch.cumsum(sorted_probs, dim=-1)\n",
    "    \n",
    "        # # keep tokens until cumulative prob <= p\n",
    "        # mask = cumulative <= p\n",
    "        # # always include at least 1 token\n",
    "        # mask[..., 0] = True\n",
    "    \n",
    "        # nucleus_probs = sorted_probs[mask]\n",
    "        # nucleus_idx = sorted_idx[mask]\n",
    "    \n",
    "        # # renormalize\n",
    "        # nucleus_probs = nucleus_probs / nucleus_probs.sum()\n",
    "    \n",
    "        # # sample from nucleus distribution\n",
    "        # next_id = torch.multinomial(nucleus_probs, 1).item()\n",
    "        # next_id = nucleus_idx[next_id].item()\n",
    "        # # -------------------------------------\n",
    "        sorted_probs, sorted_idx = torch.sort(probs.squeeze(0), descending=True)\n",
    "        cumulative = torch.cumsum(sorted_probs, dim=0)\n",
    "        cutoff = cumulative > p\n",
    "        if cutoff.any():\n",
    "            cutoff_idx = cutoff.nonzero(as_tuple=True)[0][0]\n",
    "            sorted_probs = sorted_probs[:cutoff_idx + 1]\n",
    "            sorted_idx = sorted_idx[:cutoff_idx + 1]\n",
    "        sorted_probs = sorted_probs / sorted_probs.sum()\n",
    "        next_id = sorted_idx[torch.multinomial(sorted_probs, 1)].item()\n",
    "        \n",
    "        \n",
    "        # block EOS until min_len\n",
    "        if words < min_len and next_id == EOS:\n",
    "            # continue\n",
    "            next_id = torch.argmax(probs).item()\n",
    "            \n",
    "        if next_id == EOS:\n",
    "            generated.append(EOS)\n",
    "            break\n",
    "    \n",
    "        generated.append(next_id)\n",
    "        words += 1\n",
    "\n",
    "    # print(\"Token IDs:\", generated)   # DEBUG\n",
    "    # print(\"Raw Decode:\", tokenizer.decode(generated))  # DEBUG\n",
    "\n",
    "    # return tokenizer.decode(generated[1:-1], skip_special_tokens=True)\n",
    "    return tokenizer.decode(generated, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 139090,
     "status": "ok",
     "timestamp": 1764675599604,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "8h3TSGeP83Rs",
    "outputId": "474185fd-7782-46d5-de58-d64137ae4c72"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Reports: 100%|██████████████████████████████████████████████████████████| 1311/1311 [38:08<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated reports for 10487 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "generated_list = []\n",
    "ground_truth_list = []\n",
    "img1_paths = []\n",
    "img2_paths = []\n",
    "count = 0\n",
    "\n",
    "total_batches = len(test_loader)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    # Single tqdm bar for batches\n",
    "    for batch in tqdm(test_loader, total=total_batches, desc=\"Generating Reports\"):\n",
    "\n",
    "        img1 = batch[\"img1\"].to(device)\n",
    "        img2 = batch[\"img2\"].to(device)\n",
    "        tokens = batch[\"tokens\"].to(device)\n",
    "\n",
    "        B = img1.size(0)\n",
    "\n",
    "        for i in range(B):\n",
    "            # if count>=100:\n",
    "            #     break;\n",
    "            img1_paths.append(batch[\"img1_path\"][i])\n",
    "            img2_paths.append(batch[\"img2_path\"][i])\n",
    "            ground_truth_list.append(batch[\"report\"][i])\n",
    "\n",
    "            # ===== Generate report =====\n",
    "            gen_report = generate_report(\n",
    "                encoder,\n",
    "                decoder,\n",
    "                img1[i].unsqueeze(0),\n",
    "                img2[i].unsqueeze(0),\n",
    "                A_hat.to(device),\n",
    "                X_nodes.to(device),\n",
    "                min_len=120\n",
    "            )\n",
    "\n",
    "            # ===== Ground truth =====\n",
    "            gt_report = tokenizer.decode(tokens[i].tolist(), skip_special_tokens=True)\n",
    "\n",
    "            generated_list.append(gen_report)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "print(f\"\\nGenerated reports for {count} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1764675637564,
     "user": {
      "displayName": "Shyam Varadharajan",
      "userId": "16213075368743776588"
     },
     "user_tz": -330
    },
    "id": "JdyFGvT99A-c",
    "outputId": "17439bc4-af26-476f-e34a-4ee75d913f7f"
   },
   "outputs": [],
   "source": [
    "# generated_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved at: D:\\fyp_manish_shyam\\results\\raw_output_100.csv\n"
     ]
    }
   ],
   "source": [
    "df_results_raw_100 = pd.DataFrame({\n",
    "    \"img1_path\": img1_paths[:100],\n",
    "    \"img2_path\": img2_paths[:100],\n",
    "    \"ground_truth\": ground_truth_list[:100],\n",
    "    \"generated_report\": generated_list[:100]\n",
    "})\n",
    "save_path = r\"D:\\fyp_manish_shyam\\results\\raw_output_100.csv\"\n",
    "df_results_raw_100.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"CSV saved at:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved at: D:\\fyp_manish_shyam\\results\\raw_output_fixed_bug.csv\n"
     ]
    }
   ],
   "source": [
    "df_results_raw = pd.DataFrame({\n",
    "    \"img1_path\": img1_paths,\n",
    "    \"img2_path\": img2_paths,\n",
    "    \"ground_truth\": ground_truth_list,\n",
    "    \"generated_report\": generated_list\n",
    "})\n",
    "\n",
    "save_path = r\"D:\\fyp_manish_shyam\\results\\raw_output_fixed_bug.csv\"\n",
    "df_results_raw.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"CSV saved at:\", save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.52.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (2.41.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.52.0)\n",
      "Collecting google-genai\n",
      "  Downloading google_genai-1.55.0-py3-none-any.whl.metadata (47 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.14.1->google-genai) (2.41.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (2.12.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (2.32.5)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (4.15.0)\n",
      "Collecting distro<2,>=1.7.0 (from google-genai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-genai) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (2.10)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (6.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.9.0->google-genai) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-auth[requests]<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
      "Downloading google_genai-1.55.0-py3-none-any.whl (703 kB)\n",
      "   ---------------------------------------- 0.0/703.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 703.4/703.4 kB ?  0:00:00\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, google-genai\n",
      "\n",
      "  Attempting uninstall: google-genai\n",
      "\n",
      "    Found existing installation: google-genai 1.52.0\n",
      "\n",
      "    Uninstalling google-genai-1.52.0:\n",
      "\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "      Successfully uninstalled google-genai-1.52.0\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   -------------------- ------------------- 1/2 [google-genai]\n",
      "   ---------------------------------------- 2/2 [google-genai]\n",
      "\n",
      "Successfully installed distro-1.9.0 google-genai-1.55.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\student\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"<api_key>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "Embedding Gecko\n",
      "models/gemini-2.5-flash\n",
      "Gemini 2.5 Flash\n",
      "models/gemini-2.5-pro\n",
      "Gemini 2.5 Pro\n",
      "models/gemini-2.0-flash-exp\n",
      "Gemini 2.0 Flash Experimental\n",
      "models/gemini-2.0-flash\n",
      "Gemini 2.0 Flash\n",
      "models/gemini-2.0-flash-001\n",
      "Gemini 2.0 Flash 001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "Gemini 2.0 Flash (Image Generation) Experimental\n",
      "models/gemini-2.0-flash-lite-001\n",
      "Gemini 2.0 Flash-Lite 001\n",
      "models/gemini-2.0-flash-lite\n",
      "Gemini 2.0 Flash-Lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "Gemini 2.0 Flash-Lite Preview 02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "Gemini 2.0 Flash-Lite Preview\n",
      "models/gemini-exp-1206\n",
      "Gemini Experimental 1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "Gemini 2.5 Flash Preview TTS\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "Gemini 2.5 Pro Preview TTS\n",
      "models/gemma-3-1b-it\n",
      "Gemma 3 1B\n",
      "models/gemma-3-4b-it\n",
      "Gemma 3 4B\n",
      "models/gemma-3-12b-it\n",
      "Gemma 3 12B\n",
      "models/gemma-3-27b-it\n",
      "Gemma 3 27B\n",
      "models/gemma-3n-e4b-it\n",
      "Gemma 3n E4B\n",
      "models/gemma-3n-e2b-it\n",
      "Gemma 3n E2B\n",
      "models/gemini-flash-latest\n",
      "Gemini Flash Latest\n",
      "models/gemini-flash-lite-latest\n",
      "Gemini Flash-Lite Latest\n",
      "models/gemini-pro-latest\n",
      "Gemini Pro Latest\n",
      "models/gemini-2.5-flash-lite\n",
      "Gemini 2.5 Flash-Lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "Nano Banana\n",
      "models/gemini-2.5-flash-image\n",
      "Nano Banana\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "Gemini 2.5 Flash Preview Sep 2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "Gemini 2.5 Flash-Lite Preview Sep 2025\n",
      "models/gemini-3-pro-preview\n",
      "Gemini 3 Pro Preview\n",
      "models/gemini-3-pro-image-preview\n",
      "Nano Banana Pro\n",
      "models/nano-banana-pro-preview\n",
      "Nano Banana Pro\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "Gemini Robotics-ER 1.5 Preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "Gemini 2.5 Computer Use Preview 10-2025\n",
      "models/deep-research-pro-preview-12-2025\n",
      "Deep Research Pro Preview (Dec-12-2025)\n",
      "models/embedding-001\n",
      "Embedding 001\n",
      "models/text-embedding-004\n",
      "Text Embedding 004\n",
      "models/gemini-embedding-exp-03-07\n",
      "Gemini Embedding Experimental 03-07\n",
      "models/gemini-embedding-exp\n",
      "Gemini Embedding Experimental\n",
      "models/gemini-embedding-001\n",
      "Gemini Embedding 001\n",
      "models/aqa\n",
      "Model that performs Attributed Question Answering.\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "Imagen 4 (Preview)\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "Imagen 4 Ultra (Preview)\n",
      "models/imagen-4.0-generate-001\n",
      "Imagen 4\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "Imagen 4 Ultra\n",
      "models/imagen-4.0-fast-generate-001\n",
      "Imagen 4 Fast\n",
      "models/veo-2.0-generate-001\n",
      "Veo 2\n",
      "models/veo-3.0-generate-001\n",
      "Veo 3\n",
      "models/veo-3.0-fast-generate-001\n",
      "Veo 3 fast\n",
      "models/veo-3.1-generate-preview\n",
      "Veo 3.1\n",
      "models/veo-3.1-fast-generate-preview\n",
      "Veo 3.1 fast\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "Gemini 2.5 Flash Native Audio Latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "Gemini 2.5 Flash Native Audio Preview 09-2025\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key = \"<api_key>\")\n",
    "models = client.models.list()\n",
    "for m in models:\n",
    "    print(m.name)\n",
    "    print(m.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refine_report_gemini(raw_report: str) -> str:\n",
    "    \"\"\"\n",
    "    Refine a medical report using Gemini Pro (google-genai client)\n",
    "    No Vertex AI, no Google Cloud billing.\n",
    "    \"\"\"\n",
    "\n",
    "    client = genai.Client()   # Reads GEMINI_API_KEY automatically\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a clinical radiology report editor.\n",
    "\n",
    "Rewrite the following garbled medical report into readable English:\n",
    "\n",
    "\"{raw_report}\"\n",
    "\n",
    "Rules:\n",
    "- Fix grammar.\n",
    "- Do NOT add new clinical findings.\n",
    "- Only reorganize and clean what is already present.\n",
    "- Return only the refined report.\n",
    "\"\"\"\n",
    "\n",
    "    # Correct usage for this version:\n",
    "    response = client.models.generate_content(\n",
    "        model=\"models/gemini-2.5-pro\",   # or gemini-2.5-flash\n",
    "        contents=prompt\n",
    "    )\n",
    "\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_reports = []\n",
    "failed_indices = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for idx, gen in enumerate(tqdm(generated_list, desc=\"Refining reports\")):\n",
    "    try:\n",
    "        refined = refine_report_gemini(gen)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Refinement failed at index {idx}: {e}\")\n",
    "        refined = gen\n",
    "        failed_indices.append(idx)\n",
    "\n",
    "    refined_reports.append(refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed indices saved to failed_indices.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "log_dir = r\"D:\\fyp_manish_shyam\\logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "file_path = os.path.join(log_dir, \"failed_indices.json\")\n",
    "\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(failed_indices, f)\n",
    "\n",
    "print(\"Failed indices saved to failed_indices.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\n",
    "    \"img1_path\": img1_paths[:50],\n",
    "    \"img2_path\": img2_paths[:50],\n",
    "    \"ground_truth\": ground_truth_list[:50],\n",
    "    \"generated_report\": refined_reports[:50]\n",
    "})\n",
    "\n",
    "save_path = r\"D:\\fyp_manish_shyam\\results\\final_output.csv\"\n",
    "df_results.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"CSV saved at:\", save_path)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPYWb/Awv8BUliU2CH188ht",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (dl GPU)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
